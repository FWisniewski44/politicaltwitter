[
  {
    "objectID": "methodik_erlaeuterungen.html",
    "href": "methodik_erlaeuterungen.html",
    "title": "Methodisches Vorgehen",
    "section": "",
    "text": "Die Zielsetzung der Masterarbeit ist es, wechselseitige Interaktionen medialer und politischer Akteure auf Twitter zu “kartografieren” – d. h. in erster Linie, diese sichtbar und nachverfolgbar zu machen, um dadurch ein besseres Verständnis über…:\nA. … die Interaktionen dieser Sphären miteinander auf Twitter zu erhalten\nB. … Twitter selbst als Medium politischer und medialer Interaktion zu erlangen\nUm eine solche Analyse durchführen zu können wurde sich für ein zweistufiges Verfahren entschieden, ausgehend von den dafür mittels Webscraping erhaltenen und aufbereiteten Tweet-Daten der jeweiligen Akteure (vgl. u. a. vorherige Sektion zum Datenteil):\n\nIn einem ersten Schritt müssen die Themen erschlossen werden, zu welchen die jeweiligen Akteursgruppen Tweets absetzen.\nIn einem zweiten Schritt müssen die Tweets der Akteure diesen Themen zugeordnet werden.\n\n\n\nDiese Methodik wurde gewählt, um die Themen zu identifizieren, über die die Akteure der Datensätze im Querschnitt auf Twitter schreiben. Genauer spezifiziert wurde sich für die Methodik der Topic Models mittels LDA (Latent Dirichlet Allocation) entschieden.\nBeim Topic Modeling wird ein Dokumentenkorpus (hier: Datensatz mit allen Tweets einer Akteursgruppe) verstanden als zusammengesetzt aus den einzelnen Dokumenten, die in ihm existieren. Diese Dokumente (hier: Tweets) behandeln demnach einzelne Themen, die es gilt, herauszufiltern. Bei Topic Models ist das Ergebnis eine Sammlung einer zuvor deklarierten Anzahl Themen k, welche aus einem bestimmten Set an Worten bestehen. Um aus diesen k Themen dann Sinn zu erschließen, werden diese Wörter in der Auswertung durch ein Individuum betrachtet – dies macht den qualitativen Teil der Topic Models aus.\nWichtig ist darüber hinaus auch, dass ein Dokument mehr als nur ein Thema behandeln kann, i. e.: ein Tweet kann potentiell mehr als nur ein Thema besprechen. Dies ist u. a. auch ein Grund, weshalb sich für diese Herangehensweise entschieden wurde, denn die Vermutung liegt nahe, dass in Datensätzen von Medien und PolitikerInnen Themen existieren, die einige Überschneidungen miteinander aufweisen und daher auch gemeinsam in Wortmeldungen adressiert werden könnten.\nEin zweiter Grund, weshalb sich für das Topic Modeling mittels LDA entschieden worden ist, liegt darin, dass durch diese Methodik quantitative und qualitative Arbeitscharakteristika miteinander verwoben werden. In einem ersten, quantitativen Analyseschritt werden die großen Datenmengen mittels eines unsupervised-learning-Modells erschlossen. Im zweiten Schritt werden aus den Ergebnissen (i. e. identifizierten Wortzusammenhängen) von Schritt eins qualitativ Lehren gezogen und Themen gebildet.\nDie Herangehensweise der Masterarbeit ist dabei wie folgt und orientiert sich am CrISP-DM mit den dort implementierten Feedback-Loops:\n\n\n\nSchaubild zum CrISP-DM\n\n\n\nData Preparation 1: Scraping der Tweets der jeweiligen Akteursgruppen, anschließende Speicherung als CSV-Dateien\nData Preparation 2: Bereinigung der CSV-Dateien und Daten in die für LDA vorgesehene Form bringen\nModeling: mittels R die LDA-Modelle spezifizieren, rechnen, auswerten (quantitativer Schritt)\nEvaluation: Ergebnisse der LDA-Modelle interpretieren (qualitativer Schritt)\nDeployment: Übergang zu Schritt zwei des Vorgehens, Nutzung der erhaltenen Themen zur Klassifikation\n\nZwischen diesen so beschriebenen Schritten kommt es zu den Feedback-Loops. Diese traten besonders ab dem Teil 2 des Schrittes Data Preparation häufiger auf und erwiesen sich als nützlich, um die Sinnhaftigkeit der durchgeführten Operationen immer wieder neu zu bewerten.\n\n\n\nNachdem die Daten mit Hilfe des beschriebenen Vorgehens und der Topic Models vorbereitet wurden, wurde sich zur Klassifikation der einzelnen Tweets (d. h. zur Einteilung dieser in die erhaltenen Themen) für die Herangehensweise mittels Bag of Words-Modellen entschieden.\nDer Vorteil dieser ist es, dass hier bereits Wörter aus der Auswertung der LDA vorlagen, um die einzelnen Themen zu bestücken. Es wurde sich zunächst dafür entschieden, die “Bags” auf alle Datensätze gleich anzuwenden, um somit später gute Vergleichbarkeit zu erzielen. Dazu wurden die mittels LDA erlangten Themen sowie deren zugehörige Wörterlisten in bereingiter Form als Grundlage benutzt. Bereinigt bedeutete hier, diejenigen Wörter auszuschließen, welche ohne gedanklichen Kontext in einer späteren Zuordnung durch die Bag of Words-Modelle zu viel Ambiguität aufweisen würden; es wurden also in einem qualitativen Auswahlprozess zu diesem Grundstock an Wörtern nur diejenigen übernommen, die möglichst eindeutig ihr Thema beschrieben.\nDas weitere Vorgehen gestaltete sich nun wie folgt:\n\nErstellung eines “Wörterbuchs” bzw. einer Kategorienliste mit jeweils diese Kategorien repräsentierenden Wörtern in Python\nQualitative Ergänzung des Wörterbuches durch…:\n\n… induktive Erschließung (potentiell) relevanter Wörter zu den jeweiligen Themen durch den Autor\n… deduktive Ableitung relevanter Wörter mittels Feedback-Loops durch immer wieder neue Durchgänge der Klassifikation mit anschließender Auswertung (i. e. “Wort A wird als relevant anerkannt, also ist wahrscheinlich auch Wort B relevant, da die beiden semantisch ähnlich sind”)\n… Einbeziehung unterschiedlicher Schreibweisen von Wörtern\n\n\nDurch die stetige Erweiterung des Wörterbuches auf die beschriebene Weise wurde es ermöglicht, die Bag of Words-Modelle immer genauer werden zu lassen, indem falsche Klassifikationen durch Ambiguitäten und potentielles “Übersehen” eines Tweets (und damit dessen Nicht-Klassifikation) ausgeschlossen werden konnten."
  },
  {
    "objectID": "methodik_erlaeuterungen.html#ad-1-topic-models-zur-identifizierung-der-themen",
    "href": "methodik_erlaeuterungen.html#ad-1-topic-models-zur-identifizierung-der-themen",
    "title": "Methodisches Vorgehen",
    "section": "",
    "text": "Diese Methodik wurde gewählt, um die Themen zu identifizieren, über die die Akteure der Datensätze im Querschnitt auf Twitter schreiben. Genauer spezifiziert wurde sich für die Methodik der Topic Models mittels LDA (Latent Dirichlet Allocation) entschieden.\nBeim Topic Modeling wird ein Dokumentenkorpus (hier: Datensatz mit allen Tweets einer Akteursgruppe) verstanden als zusammengesetzt aus den einzelnen Dokumenten, die in ihm existieren. Diese Dokumente (hier: Tweets) behandeln demnach einzelne Themen, die es gilt, herauszufiltern. Bei Topic Models ist das Ergebnis eine Sammlung einer zuvor deklarierten Anzahl Themen k, welche aus einem bestimmten Set an Worten bestehen. Um aus diesen k Themen dann Sinn zu erschließen, werden diese Wörter in der Auswertung durch ein Individuum betrachtet – dies macht den qualitativen Teil der Topic Models aus.\nWichtig ist darüber hinaus auch, dass ein Dokument mehr als nur ein Thema behandeln kann, i. e.: ein Tweet kann potentiell mehr als nur ein Thema besprechen. Dies ist u. a. auch ein Grund, weshalb sich für diese Herangehensweise entschieden wurde, denn die Vermutung liegt nahe, dass in Datensätzen von Medien und PolitikerInnen Themen existieren, die einige Überschneidungen miteinander aufweisen und daher auch gemeinsam in Wortmeldungen adressiert werden könnten.\nEin zweiter Grund, weshalb sich für das Topic Modeling mittels LDA entschieden worden ist, liegt darin, dass durch diese Methodik quantitative und qualitative Arbeitscharakteristika miteinander verwoben werden. In einem ersten, quantitativen Analyseschritt werden die großen Datenmengen mittels eines unsupervised-learning-Modells erschlossen. Im zweiten Schritt werden aus den Ergebnissen (i. e. identifizierten Wortzusammenhängen) von Schritt eins qualitativ Lehren gezogen und Themen gebildet.\nDie Herangehensweise der Masterarbeit ist dabei wie folgt und orientiert sich am CrISP-DM mit den dort implementierten Feedback-Loops:\n\n\n\nSchaubild zum CrISP-DM\n\n\n\nData Preparation 1: Scraping der Tweets der jeweiligen Akteursgruppen, anschließende Speicherung als CSV-Dateien\nData Preparation 2: Bereinigung der CSV-Dateien und Daten in die für LDA vorgesehene Form bringen\nModeling: mittels R die LDA-Modelle spezifizieren, rechnen, auswerten (quantitativer Schritt)\nEvaluation: Ergebnisse der LDA-Modelle interpretieren (qualitativer Schritt)\nDeployment: Übergang zu Schritt zwei des Vorgehens, Nutzung der erhaltenen Themen zur Klassifikation\n\nZwischen diesen so beschriebenen Schritten kommt es zu den Feedback-Loops. Diese traten besonders ab dem Teil 2 des Schrittes Data Preparation häufiger auf und erwiesen sich als nützlich, um die Sinnhaftigkeit der durchgeführten Operationen immer wieder neu zu bewerten."
  },
  {
    "objectID": "methodik_erlaeuterungen.html#ad-2-bag-of-words-modelle-zur-klassifizierung-der-tweets-nach-themen",
    "href": "methodik_erlaeuterungen.html#ad-2-bag-of-words-modelle-zur-klassifizierung-der-tweets-nach-themen",
    "title": "Methodisches Vorgehen",
    "section": "",
    "text": "Nachdem die Daten mit Hilfe des beschriebenen Vorgehens und der Topic Models vorbereitet wurden, wurde sich zur Klassifikation der einzelnen Tweets (d. h. zur Einteilung dieser in die erhaltenen Themen) für die Herangehensweise mittels Bag of Words-Modellen entschieden.\nDer Vorteil dieser ist es, dass hier bereits Wörter aus der Auswertung der LDA vorlagen, um die einzelnen Themen zu bestücken. Es wurde sich zunächst dafür entschieden, die “Bags” auf alle Datensätze gleich anzuwenden, um somit später gute Vergleichbarkeit zu erzielen. Dazu wurden die mittels LDA erlangten Themen sowie deren zugehörige Wörterlisten in bereingiter Form als Grundlage benutzt. Bereinigt bedeutete hier, diejenigen Wörter auszuschließen, welche ohne gedanklichen Kontext in einer späteren Zuordnung durch die Bag of Words-Modelle zu viel Ambiguität aufweisen würden; es wurden also in einem qualitativen Auswahlprozess zu diesem Grundstock an Wörtern nur diejenigen übernommen, die möglichst eindeutig ihr Thema beschrieben.\nDas weitere Vorgehen gestaltete sich nun wie folgt:\n\nErstellung eines “Wörterbuchs” bzw. einer Kategorienliste mit jeweils diese Kategorien repräsentierenden Wörtern in Python\nQualitative Ergänzung des Wörterbuches durch…:\n\n… induktive Erschließung (potentiell) relevanter Wörter zu den jeweiligen Themen durch den Autor\n… deduktive Ableitung relevanter Wörter mittels Feedback-Loops durch immer wieder neue Durchgänge der Klassifikation mit anschließender Auswertung (i. e. “Wort A wird als relevant anerkannt, also ist wahrscheinlich auch Wort B relevant, da die beiden semantisch ähnlich sind”)\n… Einbeziehung unterschiedlicher Schreibweisen von Wörtern\n\n\nDurch die stetige Erweiterung des Wörterbuches auf die beschriebene Weise wurde es ermöglicht, die Bag of Words-Modelle immer genauer werden zu lassen, indem falsche Klassifikationen durch Ambiguitäten und potentielles “Übersehen” eines Tweets (und damit dessen Nicht-Klassifikation) ausgeschlossen werden konnten."
  },
  {
    "objectID": "datenteil_erlaeuterungen.html",
    "href": "datenteil_erlaeuterungen.html",
    "title": "Näheres zur Datengrundlage",
    "section": "",
    "text": "Hier befinden sich nähere Informationen zur Erstellung des Medien-Datensatzes durch den Autor, der eine Hälfte der Grundlage vorliegender Masterarbeit bildet. Als Datengrundlage für die PolitikerInnen wurde auf Schmidt et al (2022) zurückgegriffen.\nBei vorliegenden Erläuterungen handelt es sich um eine Ergänzung des theoretischen Rahmens der Masterarbeit um eine Darlegung des praktischen Vorgehens zur weiteren und tiefergehenden Illustration."
  },
  {
    "objectID": "datenteil_erlaeuterungen.html#erreichbarkeit-reichweite-der-medien-erreichbarkeit-der-menschen-durch-medien",
    "href": "datenteil_erlaeuterungen.html#erreichbarkeit-reichweite-der-medien-erreichbarkeit-der-menschen-durch-medien",
    "title": "Näheres zur Datengrundlage",
    "section": "Erreichbarkeit: Reichweite der Medien, Erreichbarkeit der Menschen durch Medien",
    "text": "Erreichbarkeit: Reichweite der Medien, Erreichbarkeit der Menschen durch Medien\nVorliegende Arbeit hat sich bei der Benennung der Variable für den Begriff der Erreichbarkeit entschieden. Im Originalbeitrag der genannten Autoren könnte man dies jedoch auch als “Reichweite” interpretieren, nämlich jene Reichweite der Medien, die ihnen die Möglichkeit gibt, eine gewisse, unterschiedlich große Anzahl an Menschen mit ihren Beiträgen zu erreichen.\nIm angesprochenen Paper waren drei Kategorien vorgesehen, um die mediale Reichweite zu erfassen:\n\nEtablierte Akteure\nAlternative Akteure\nIndividuelle Akteure\n\nEtablierte Akteure (große Tageszeitungen, TV-Sendungen) können regelmäßig ein großes Publikum erreichen. Alternative Akteure (Blogs, kleinere Nachrichtenwebseiten) hätten laut Theorie ein kleineres, dafür stärker an sie gebundenes Publikum, was z. T. auch daran liegt, dass sie eher eine gewisse Meinung vertreten bzw. Partei ergreifen würden. Individuelle Akteure (PolitikerInnen, gesellschaftliche “opinion leaders”) haben dagegen nicht die gleiche Massenwirkung wie die ersten beiden Kategorien, jedoch potentiell eine noch größere Unabhängigkeit was Themensetzung und Vergleichbares betrifft. Die diskursive Machtfülle der Akteure nimmt generell gesprochen von Kategorie 1 bis Kategorie 3 hin immer mehr ab.\nDie Einteilung wurde in vorliegender Arbeit übernommen, jedoch minimal modifiziert, indem die Kategorie “etablierte Akteure” nochmals unterteilt wurde. Der Hintergedanke hierbei war es, sowohl auf der überregionalen als auch auf der regionalen Ebene derartige Akteure unterscheiden zu können, die für ihre Verhältnisse viele Menschen zu erreichen vermögen.\nAndernfalls hätte das bedeutet, alle regionalen oder lokalen Medien in die Kategorie “alternative Akteure” zu sortieren, da diese zweifelsohne – in absoluten Zahlen gedacht – weniger Menschen erreichen können. Es wäre dennoch ein Trugschluss, wenn angenommen würde, dass lokale oder regionale Medien nicht auch einen starken Einfluss auf die jeweilige Leserschaft ausüben können. So ist es denkbar, dass z. B. eine Regionalzeitung den Großteil der Haushalte ihrer jeweiligen Region erreicht; dies wäre zwar noch immer viel weniger, als eine überregionale Tageszeitung erreichen könnte, dennoch weist diese Regionalzeitung dadurch zweifelsohne nach, dass sie in einem ihr möglichen Rahmen als etabliert angesehen werden muss. Es ergibt sich also folgendes Schema:\n\n\n\nWert\nBezeichnung\n\n\n\n\n1\nEtablierter Akteur (überregional)\n\n\n2\nEtablierter Akteur (regional)\n\n\n3\nAlternativer Akteur\n\n\n4\nIndividueller Akteur"
  },
  {
    "objectID": "datenteil_erlaeuterungen.html#normenwerte-moralischer-kompass-der-medien",
    "href": "datenteil_erlaeuterungen.html#normenwerte-moralischer-kompass-der-medien",
    "title": "Näheres zur Datengrundlage",
    "section": "NormenWerte: “moralischer Kompass” der Medien",
    "text": "NormenWerte: “moralischer Kompass” der Medien\nDie zweite Kategorie der “discursive power”-Theorie beschäftigt sich mit den Normen und Werten in der Berichterstattung medialer Akteure. Dieser moralische Kompass der Medien, dem diese folgen, gibt somit vor, welche Themen überhaupt von Interesse für einen Akteur sein könnten bzw. wie dieser die Themen in der Folge dann auch bearbeitet – und somit auch implizit, an welches Publikum sich vorrangig gerichtet werden soll. Die Autoren identifizieren dabei erneut einen Dreiklang:\n\nObjektiv-ausbalanciertes Berichten\nParteiisches Berichten\nMarktgetriebenes Berichten\n\nMedien des objektiv-ausbalancierten Typus unternähmen demnach den Versuch, ihre Berichterstattung und Themenauswahl nach der (wahrgenommenen) gesellschaftlichen Relevanz auszurichten. Die des parteiischen Berichtens sortieren ihre Themen idealtypisch gesehen dahingehend aus, dass nur die aufgenommen werden, die der jeweiligen dahinterstehenden Partei (Anmerkung: dies ist nicht zwangsläufig politisch zu verstehen) dienlich sind. Im marktgetriebenen Berichten stehen hingegen die (wahrgenommenen) Bedürfnisse der Leserschaft im Vordergrund; d. h. hier werden schockierende und auch unterhaltende Themen aufgegriffen. Vorliegende Arbeit ergänzt dies noch um eine vierte Kategorie: jene Akteure, die nicht in eine der anderen drei Kategorien passen. Damit ergibt sich:\n\n\n\nWert\nBezeichnung\n\n\n\n\n1\nObjektiv-ausbalanciertes Berichten\n\n\n2\nParteiisches Berichten\n\n\n3\nMarktgetriebenes Berichten\n\n\n4\nNicht klassifizierbar"
  },
  {
    "objectID": "datenteil_erlaeuterungen.html#geschäftsmodell-wege-der-finanzierung",
    "href": "datenteil_erlaeuterungen.html#geschäftsmodell-wege-der-finanzierung",
    "title": "Näheres zur Datengrundlage",
    "section": "Geschäftsmodell: Wege der Finanzierung",
    "text": "Geschäftsmodell: Wege der Finanzierung\nDie dritte Größe beschäftigt sich mit der jeweiligen Finanzierung des betrachteten Mediums. Dabei unterscheidet die Theorie die folgenden drei Möglichkeiten, welche unverändert auch in vorliegender Arbeit genutzt werden:\n\n\n\nWert\nBezeichnung\n\n\n\n\n1\nÖffentliche Finanzierung\n\n\n2\nKommerzielle Finanzierung\n\n\n3\nFinanzierung über Spenden; Vereine\n\n\n\nMedien mit öffentlicher Finanzierung beziehen ihre Geldmittel durch staatliche Mittel oder anderweitige Organisationen der öffentlichen Hand. Diese sind besonders in Deutschland von großer Bedeutung (vgl. ARD/ZDF sowie die “dritten Programme” der jeweiligen Regionen). Bei kommerzieller Finanzierung wurden diejenigen Medien einsortiert, die den gängigen Mechanismen marktwirtschaftlichen Handelns unterworfen sind; d. h., dass diese zur Finanzierung des eigenen Handels auf gewissen Umsatz angewiesen sind. Schließlich erfasst die Kategorie der Finanzierung über Spenden bzw. über Vereinsstrukturen jene Medien, die z. B. durch Gelder von Großspendern oder Crowdfunding finanziert werden oder sich über eine Stiftung bzw. einen Verein Gelder erwirtschaften.\nDiese Hintergründe der Finanzierung verweisen auch auf einen gewissen Handlungsimpetus der jeweiligen Akteure, weshalb es sinnvoll ist, diese Größe mit zu erheben."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Twitter-Deutschland zwischen Medien und Politik",
    "section": "",
    "text": "Diese Webseite beinhaltet den Online-Appendix zur Masterarbeit mit dem oben genannten Titel.\nSie wurde im Studiengang M. A. Politikwissenschaft mit dem Schwerpunkt Computational Social Science am Lehrstuhl für Politikwissenschaft, insbesondere Digitale Transformation der Otto-Friedrich-Universität Bamberg von Florian Wisniewski vorgelegt und durch Prof. Dr. Andreas Jungherr betreut."
  },
  {
    "objectID": "001_Testgraphik.html",
    "href": "001_Testgraphik.html",
    "title": "Visualisierung 1",
    "section": "",
    "text": "Visualisierung 1"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "Inhalte auf dieser Seite",
    "section": "",
    "text": "Der Schwerpunkt der Masterarbeit liegt auf der graphischen Aufbereitung und Analyse der Daten mittels zahlreicher Visualisierungen. Hierzu erschien es angebracht, diese nicht nur lediglich auf Papier zu betrachten, sondern auch die technischen Möglichkeiten auszunutzen und jene Visualisierungen auch auf diesem Weg zugänglich zu machen.\nDabei seien folgende Punkte klargestellt:\n\nDie Visualisierungen, die auf dieser Seite aufgeführt sind, sind im Sinne eines Online-Appendix als Ergänzungen zu jenen zu sehen, die in der Abgabeform der Arbeit genutzt wurden.\nDie schriftlichen Ausführungen auf dieser Seite sind eher praktischer Natur, d. h. Vorgänge werden verkürzt dargelegt und es steht eher die praktische Umsetzung von Problemlösungen im Zentrum.\n\nZiel ist es vorrangig, hier nochmals vereinfacht die Ziele der Arbeit klar verständlich auszudrücken, auf Besonderheiten im Bearbeitungs- und Entstehungsprozess der Arbeit einzugehen und schließlich am Zentralsten: zusätzlich ergänzende, teils interaktive Visualisierungen und graphische Aufbereitungen der Daten leichter zugänglich zu machen."
  }
]